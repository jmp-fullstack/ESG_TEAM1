{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 지속가능경영보고서 크롤링 (110/200개 기업) https://esg.krx.co.kr/contents/02/02030000/ESG02030000.jsp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 지속가능경영보고서접속링크를 포함하는 csv 파일 저장\n",
    "-> 회사명, 발행년도, 코드, 페이지접속링크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# 크롤링할 년도 범위 및 페이지 범위 설정\n",
    "years = range(2013, 2024)\n",
    "pages = range(1, 19)  # 예시로 1부터 18페이지까지 크롤링\n",
    "\n",
    "# 결과를 저장할 리스트 초기화\n",
    "data_df = []\n",
    "\n",
    "# 년도와 페이지를 모두 반복하며 크롤링 수행\n",
    "for year in years:\n",
    "    for page in pages:\n",
    "        url = 'https://esg.krx.co.kr/contents/99/ESG99000001.jspx'\n",
    "        payload = {\n",
    "            'sch_yy': year,\n",
    "            'sch_tp': 'N', \n",
    "            'pagePath': '/contents/02/02030000/ESG02030000.jsp', \n",
    "            'code': '02/02030000/esg02030000_01', \n",
    "            'curPage': page\n",
    "        }\n",
    "\n",
    "        response = requests.post(url, data=payload, headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36'})\n",
    "\n",
    "        # 응답 확인\n",
    "        if response.status_code == 200:\n",
    "            python_data = json.loads(response.text)\n",
    "            for ele in python_data['result']:\n",
    "                data_df.append([ele['com_abbrv'], ele['yy'], ele['save_file_nm']])\n",
    "        else:\n",
    "            print(f\"페이지 {page}, 년도 {year} 크롤링 실패\")\n",
    "\n",
    "# 데이터프레임 생성\n",
    "columns = ['회사명', '발행년도', '코드']\n",
    "df = pd.DataFrame(data_df, columns=columns)\n",
    "df['페이지접속링크'] = 'https://kind.krx.co.kr/common/disclsviewer.do?method=search&acptno='+df['코드']+'&docno=&viewerhost=&viewerport='\n",
    "\n",
    "# 코스피 200 기업명 리스트 가져오기\n",
    "f = open('top200_name_list.csv','r',encoding='utf-8')\n",
    "data = f.read().split('\\n')\n",
    "\n",
    "# 데이터프레임의 조직명과 코스피 200 리스트의 회사명을 비교하여 코스피 200에 속하는 행만 추출\n",
    "kospi200_companies_df = df[df['회사명'].isin(data)]\n",
    "\n",
    "# 저장\n",
    "kospi200_companies_df.to_csv('지속가능경영보고서접속링크.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. selenium 사용해 지속가능경영보고서 pdf 다운로드 링크 추가\n",
    "기존 csv 파일에 접근하여 pdf 다운로드할 수 있는 링크를 추가하여 csv 파일로 다시 저장  \n",
    "\n",
    "-> 회사명, 발행년도, 코드, 페이지접속링크 pdf다운로드링크  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('지속가능경영보고서접속링크.csv')\n",
    "\n",
    "# 웹 드라이버 초기화\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "# 새로운 열 생성 및 초기화\n",
    "df['pdf다운로드링크'] = ''\n",
    "\n",
    "# 데이터프레임 반복문\n",
    "for index, row in df.iterrows():\n",
    "    # 웹사이트에 접속\n",
    "    driver.get(row['페이지접속링크'])\n",
    "\n",
    "    # 요소 클릭\n",
    "    try:\n",
    "        WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, 'attachedDoc'))).click()\n",
    "    except:\n",
    "        print(\"요소를 찾을 수 없습니다.\")\n",
    "        print(index, row)\n",
    "        print(row['페이지접속링크'])\n",
    "        continue\n",
    "\n",
    "    # 두 번째 옵션 클릭\n",
    "    try:\n",
    "        options = WebDriverWait(driver, 10).until(EC.visibility_of_all_elements_located((By.XPATH, \"//select[@id='attachedDoc']/option\")))\n",
    "        if len(options) > 1:\n",
    "            options[1].click()  # 두 번째 옵션 선택\n",
    "    except:\n",
    "        print(\"옵션을 찾을 수 없습니다.\")\n",
    "        continue\n",
    "\n",
    "    # iframe 전환\n",
    "    try:\n",
    "        driver.switch_to.frame('docViewFrm')\n",
    "    except:\n",
    "        print(\"iframe을 찾을 수 없습니다.\")\n",
    "        continue\n",
    "\n",
    "    # PDF 다운로드 링크 가져오기\n",
    "    try:\n",
    "        pdf_download_link = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"/html/body/div/div/a\"))).get_attribute('href')\n",
    "        # 데이터프레임에 저장\n",
    "        df.at[index, 'pdf다운로드링크'] = pdf_download_link\n",
    "    except:\n",
    "        print(\"PDF 다운로드 링크를 찾을 수 없습니다.\")\n",
    "        df.at[index, 'pdf다운로드링크'] = None\n",
    "\n",
    "# 웹 드라이버 종료\n",
    "driver.close()\n",
    "driver.quit()\n",
    "\n",
    "# df.isnull().sum() # 결측치 개수 확인\n",
    "\n",
    "# 결측치인 행의 인덱스 반환 -> 24\n",
    "df['pdf다운로드링크'][df['pdf다운로드링크'].isnull()]\n",
    "\n",
    "# 결측치가 존재하는 행  제거\n",
    "df = df.drop(24)\n",
    "\n",
    "df.to_csv('지속가능경영보고서다운로드링크추가.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. pdf 파일 저장\n",
    "해당 경로에 pdf 파일 저장할 폴더\"pdf\" 생성 후, pdf 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf 다운로드\n",
    "import os\n",
    "import urllib.request\n",
    "import traceback\n",
    "import pandas as pd\n",
    "\n",
    "df2 = pd.read_csv('지속가능경영보고서다운로드링크추가.csv')\n",
    "\n",
    "total_info = [tuple(row) for row in df2.values] # 데이터프레임을 리스트 안의 튜플 데이터 형태로 변환\n",
    "\n",
    "dir = './pdf/' # pdf 파일 저장할 경로 설정\n",
    "if not os.path.exists(dir): # 폴더 없는 경우에 생성하는 코드\n",
    "    os.makedirs(dir)\n",
    "\n",
    "for i in range(len(total_info)):\n",
    "    if i==0:\n",
    "        print('pdf 다운로드 시작')\n",
    "    try:\n",
    "        file_name = total_info[i][0]+'_'+str(total_info[i][1])+'.pdf'\n",
    "        urllib.request.urlretrieve(total_info[i][4], dir+file_name)\n",
    "    except:\n",
    "        print(f\"error : {total_info[i][0]}\")\n",
    "        print(traceback.format_exc())\n",
    "        i += 1 # 에러가 발생한 경우, 해당 항목부터 다시 크롤링할 수 있도록 i를 1 증가시킴\n",
    "    if i!=0 and i%100==0:\n",
    "        print(f'pdf 다운로드 진행률 : {i}/{len(total_info)}') # 100개 다운로드마다 알림\n",
    "print('완료')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. pdf 파일에 접근해 텍스트만 가져와 전처리하여 기존 csv 파일에 저장\n",
    "-> 회사명, 발행년도, 코드, 페이지접속링크 pdf다운로드링크 내용  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz\n",
    "import kss\n",
    "import pandas as pd\n",
    "\n",
    "df3 = pd.read_csv('지속가능경영보고서다운로드링크추가.csv')\n",
    "\n",
    "pdf_path = os.getcwd() + '\\\\pdf\\\\'\n",
    "\n",
    "final_list = []\n",
    "for idx, row in df3.iterrows():\n",
    "    pdf_file_path = pdf_path + row['회사명'] + '_' + str(row['발행년도']) + '.pdf'\n",
    "    try:\n",
    "        with fitz.open(pdf_file_path) as doc:\n",
    "            contents = ''\n",
    "            for page in doc:\n",
    "                contents += page.get_text()\n",
    "            sents = kss.split_sentences(contents)\n",
    "            sents = [sent.replace('\\n', '') for sent in sents]\n",
    "\n",
    "            new_sentences = []\n",
    "            for sent in sents:\n",
    "                # Split the sentence by both '.' and 'ㆍ'\n",
    "                sub_sentences = sent.replace('ㆍ', '.').split('.')\n",
    "                # Add each sub-sentence to the new list\n",
    "                new_sentences.extend(sub_sentences)\n",
    "            new_sentences = [sent.strip() for sent in new_sentences if sent.strip()]\n",
    "\n",
    "            sentences = [sent for sent in new_sentences if sent.endswith('다')] # 다로 끝나는 것들만 모아서 문장취급함\n",
    "            final_list.append(sentences)\n",
    "    except:\n",
    "        print('해당파일 제외 :', pdf_file_path)\n",
    "        # 파일을 열 수 없는 경우 None 값을 추가합니다.\n",
    "        final_list.append(None)\n",
    "\n",
    "# 데이터프레임을 복제하여 새로운 데이터프레임을 생성합니다.\n",
    "new_df = df3.copy()\n",
    "\n",
    "# '내용' 열을 final_list의 각 항목으로 설정합니다.\n",
    "new_df['내용'] = final_list\n",
    "\n",
    "# 수정된 데이터프레임을 출력합니다.\n",
    "new_df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
