{"cells":[{"cell_type":"markdown","metadata":{"id":"ColxfM_LfK4K"},"source":["# KOBERT ESG 학습\n"]},{"cell_type":"markdown","metadata":{"id":"xmjhbDCEumPC"},"source":["`필요 환경 및 패키지 설치`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FSkf0n9pfK4N"},"outputs":[],"source":["!pip install mxnet\n","!pip install pandas tqdm\n","!pip install sentencepiece\n","!pip install transformers\n","!pip install torch\n","!pip install gluonnlp==0.10.0\n","!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer\u0026subdirectory=kobert_hf'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q1KvuoVJkrgM"},"outputs":[],"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","\n","import gluonnlp as nlp\n","import numpy as np\n","from tqdm import tqdm, tqdm_notebook\n","from kobert_tokenizer import KoBERTTokenizer\n","from transformers import BertModel\n","\n","from transformers import AdamW\n","from transformers.optimization import get_cosine_schedule_with_warmup\n","import urllib.request\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","kobert_tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n","\n","word_tokenizer = kobert_tokenizer.tokenize\n","\n","kobertmodel = BertModel.from_pretrained('skt/kobert-base-v1', return_dict=False)\n","\n","vocab = nlp.vocab.BERTVocab.from_sentencepiece(kobert_tokenizer.vocab_file, padding_token='[PAD]')"]},{"cell_type":"markdown","metadata":{"id":"VuMpkitVIgXl"},"source":["`사전 파라미터 지정`"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":510,"status":"ok","timestamp":1713245100508,"user":{"displayName":"한상혁","userId":"05319193929852015189"},"user_tz":-540},"id":"2ttg1EPIIfem"},"outputs":[],"source":["max_len = 128\n","batch_size = 64\n","warmup_ratio = 0.1\n","num_epochs = 5\n","max_grad_norm = 1\n","log_interval = 200\n","learning_rate =  5e-5"]},{"cell_type":"markdown","metadata":{"id":"0AcJ-SoEHU9X"},"source":["`esg 데이터셋 불러오기 및 train_test_split`"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":2350,"status":"ok","timestamp":1713245107226,"user":{"displayName":"한상혁","userId":"05319193929852015189"},"user_tz":-540},"id":"02gztnFdu6p6"},"outputs":[],"source":["# esg 데이터 불러오기\n","esg_data = pd.read_csv('/content/drive/MyDrive/kobert_modeling/문장esg테스트용.csv')\n","\n","# 필요없는 정보 제거하기\n","del esg_data['Unnamed: 0']\n","\n","# 문장 라벨 묶어주기\n","esg_data_list = []\n","for sent, e_label, s_label, g_label in zip(esg_data['문장'], esg_data['E'], esg_data['S'], esg_data['G']):\n","    data = []\n","    data.append(str(sent))\n","    data.append((str(e_label), str(s_label), str(g_label)))\n","    esg_data_list.append(data)\n","\n","from sklearn.model_selection import train_test_split\n","esg_train_data, esg_valid_data = train_test_split(esg_data_list, test_size = 0.2, shuffle = True, random_state = 32)"]},{"cell_type":"markdown","metadata":{"id":"lQxaKgf5uRyr"},"source":["`esg_dataset 구축 및 dataloader 구축`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kk8GNRfOuQ2t"},"outputs":[],"source":["class ESG_BERTDataset(Dataset):\n","    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, vocab, max_len,\n","                 pad, pair):\n","        self.transform = nlp.data.BERTSentenceTransform(bert_tokenizer, max_seq_length=max_len, vocab = vocab, pad=pad, pair=pair)\n","        self.sentences = [self.transform([i[sent_idx]]) for i in dataset] # 데이터 셋의 문장들을 bert 맞춤형 토큰화 모음 리스트\n","        self.labels = torch.tensor([(int(i[label_idx][0]), int(i[label_idx][1]), int(i[label_idx][2])) for i in dataset]) # 데이터 셋의 라벨들 모음 리스트\n","        # self.labels 형태 예시 : (0,1,0)\n","    def __getitem__(self, i): # 특정 문장 특정 문장의 라벨을 리턴해줌\n","        return (self.sentences[i] + (self.labels[i], ))\n","    def __len__(self):\n","        return (len(self.labels)) # 문장 개수 리턴 해줌.\n","\n","\n","esg_data_train = ESG_BERTDataset(esg_train_data, 0, 1, word_tokenizer, vocab, max_len, True, False)\n","esg_data_test = ESG_BERTDataset(esg_valid_data, 0, 1, word_tokenizer, vocab, max_len, True, False)\n","\n","\n","# 데이터 로더 구축\n","esg_train_dataloader = torch.utils.data.DataLoader(esg_data_train, batch_size = batch_size, num_workers = 5)\n","esg_test_dataloader = torch.utils.data.DataLoader(esg_data_test, batch_size = batch_size, num_workers = 5)"]},{"cell_type":"markdown","metadata":{"id":"_1j-Bg4Kmq6J"},"source":["`ESG를 분류하는 모델`"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":623,"status":"ok","timestamp":1713245167038,"user":{"displayName":"한상혁","userId":"05319193929852015189"},"user_tz":-540},"id":"085FcR0HcBYx"},"outputs":[],"source":["class BERT_ESG_Classifier(nn.Module):\n","    def __init__(self,\n","                 bert,\n","                 hidden_size = 768,\n","                 num_classes = 3,\n","                 dr_rate = None,\n","                 params = None):\n","        super(BERT_ESG_Classifier, self).__init__()\n","        self.bert = bert\n","        self.dr_rate = dr_rate\n","        self.esg_classifier = nn.Linear(hidden_size , num_classes)\n","        if dr_rate:\n","            self.dropout = nn.Dropout(p = dr_rate)\n","        self.activation_sigmoid = nn.Sigmoid()\n","\n","    def gen_attention_mask(self, token_ids, valid_length):\n","        attention_mask = torch.zeros_like(token_ids)\n","        for i, v in enumerate(valid_length):\n","            attention_mask[i][:v] = 1\n","        return attention_mask.float()\n","\n","    def forward(self, token_ids, valid_length, segment_ids):\n","        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n","        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device), return_dict = False)\n","        if self.dr_rate:\n","            out = self.dropout(pooler)\n","        esg_score = self.esg_classifier(out)\n","        activation_esg_score = self.activation_sigmoid(esg_score)\n","        return activation_esg_score"]},{"cell_type":"markdown","metadata":{"id":"MTa0AGa3BJqv"},"source":["`esg 모델 정의하기`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HB9xXUOow9ej"},"outputs":[],"source":["# BERT  모델 불러오기\n","model = BERT_ESG_Classifier(kobertmodel,  dr_rate = 0.5).to(device)\n","\n","# kober model freezing 하기\n","for name, para in model.named_parameters() :\n","    if not name.count('esg_classifier') :\n","        para.requires_grad = False\n","\n","# 옵티마이저 생성 시 전달해줄 파라미터 정의\n","no_decay = ['bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [weight for name, weight in model.named_parameters() if not any(nd in name for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [weight for name, weight in model.named_parameters() if any(nd in name for nd in no_decay)], 'weight_decay': 0.0} ]\n","\n","\n","# 옵티마이저 정의\n","optimizer = AdamW(optimizer_grouped_parameters, lr = learning_rate)\n","\n","# 손실함수 정의\n","loss_fn = nn.BCELoss()\n","\n","# 스케쥴러 생성 시 전달해줄 파라미터 정의\n","t_total = len(esg_train_dataloader) * num_epochs\n","warmup_step = int(t_total * warmup_ratio)\n","\n","# 스케쥴러 정의\n","scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps = warmup_step, num_training_steps = t_total)"]},{"cell_type":"markdown","metadata":{"id":"ksWVE9G-BJqw"},"source":["`esg 정확도 계산 함수 정의`"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":406,"status":"ok","timestamp":1713245203588,"user":{"displayName":"한상혁","userId":"05319193929852015189"},"user_tz":-540},"id":"yMAGcjy95fHa"},"outputs":[],"source":["# esg 분류 시에 사용한다\n","def esg_calc_accuracy(X,Y):\n","    X[X \u003c= 0.5 ] = 0\n","    X[X \u003e 0.5 ] = 1\n","    answer = 0\n","    for pred in (X - Y) :\n","        if torch.abs(pred).sum() == 0 :\n","            answer += 1\n","    train_acc = answer/batch_size\n","    return train_acc"]},{"cell_type":"markdown","metadata":{"id":"d-SfDpRK12-v"},"source":["`esg 모델 학습시키기`"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":215},"id":"8yCn_oqY5_7S"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u003cipython-input-10-e973670de767\u003e:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(esg_train_dataloader)):\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0106b5b0eb6341f1b359418a66f27091","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/951 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"name":"stdout","output_type":"stream","text":["epoch : 1 | batch_id : 1 | loss : 0.6844475865364075| accuracy : 0.234375\n","epoch : 1 | batch_id : 201 | loss : 0.7116233706474304| accuracy : 0.13440609452736318\n"]}],"source":["# esg 분류 시에 사용한다.\n","for e in range(1):\n","    train_acc = 0.0\n","    model.train() # model을 훈련모드로 바꾸고, 가중치가 업데이트 될 수 있게 한다.\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(esg_train_dataloader)):\n","        # 옵티마이저의 미분값을 0으로 초기화\n","        optimizer.zero_grad()\n","\n","        # model의 forward 인자 설정\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","        valid_length= valid_length\n","        label = label.float().to(device)\n","\n","        # model output 도출\n","        out = model.forward(token_ids, valid_length, segment_ids)\n","\n","        # 모델 output과 label(정답)과의 손실함수 정의\n","        loss = loss_fn(out, label)\n","\n","        # 손실함수의 기울기 계산\n","        loss.backward()\n","\n","        # gradient vanishing 또는 gradient exploding을 방지하기 위한 gradient clipping\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n","\n","        # 기울기 반영한 가중치 업데이트\n","        optimizer.step()\n","        scheduler.step()\n","\n","        train_acc += esg_calc_accuracy(out, label)\n","\n","        if batch_id % log_interval == 0:\n","             print(f'epoch : {e+1} | batch_id : {batch_id + 1} | loss : {loss.data.cpu().numpy()}| accuracy : {train_acc / (batch_id+1)}')\n","\n","    print(\"epoch : {} train acc : {}\".format(e+1, train_acc / (batch_id+1)))"]},{"cell_type":"markdown","metadata":{"id":"SXsq_T5z2JvX"},"source":["`학습시킨 esg model 기반 esg_predict 함수`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uiTjceBh1-xn"},"outputs":[],"source":["# esg 분류시에 사용한다.\n","def esg_predict(predict_sentence):\n","    data = [predict_sentence,(0,0,0)]\n","    dataset_another = [data]\n","    another_test = ESG_BERTDataset(dataset_another, 0, 1, word_tokenizer, vocab, max_len, True, False)\n","    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size = batch_size, num_workers = 5)\n","    model.eval()\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n","        # model의 forward 인자 설정\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","        valid_length = valid_length\n","        label = label.float().to(device)\n","        # model output 도출\n","        out = model.forward(token_ids, valid_length, segment_ids)\n","        # 모델의 output은 바로 사용하지 못한다. 밑에 있는 logits 코드 이용하기\n","        for i in out:\n","            logits = i\n","            logits = logits.detach().cpu().numpy()\n","\n","    return logits\n"]},{"cell_type":"markdown","metadata":{"id":"Vv3Kf2gH2MzJ"},"source":["`esg_predict 해보기`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m8ZQ88il-J1T"},"outputs":[],"source":["# 테스트 데이터 불러오기\n","test_data = pd.read_csv('/content/drive/MyDrive/kobert_modeling/naver_news_test.csv')\n","\n","# 문장 추출\n","sents = test_data['content']\n","for i, sent in enumerate(sents[:10]) :\n","    esg_output = esg_predict(sent)\n","    print(f'{i+1}번 문장 =  E : {esg_output[0] * 100}점, S : {esg_output[1] * 100}점, G : {esg_output[2] * 100}점')"]},{"cell_type":"markdown","metadata":{"id":"kUvVojwv5EoD"},"source":["`모델 저장하기`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"llbTmXCcHNth"},"outputs":[],"source":["# 저장하기(모델 추가 계층 및 옵티마이저)\n","torch.save({'model_esg_classifier_state_dict': model.esg_classifier.state_dict()}, '/content/drive/MyDrive/model_checkpoint/esg_version1.pt')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0106b5b0eb6341f1b359418a66f27091":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7481afa84a814dedb6877f57cfebcc3c","IPY_MODEL_4a82646618204548a5d28325229c1db8","IPY_MODEL_6035bc24f0a94c7986d43246642b958a"],"layout":"IPY_MODEL_4d006a7b4bb34572bb81112be1cdcab4"}},"4a82646618204548a5d28325229c1db8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_773e2938bc3a43db9a7aa97d90d4757a","max":951,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c1d0ef825d4b47ab870ac88b78fee830","value":8}},"4d006a7b4bb34572bb81112be1cdcab4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6035bc24f0a94c7986d43246642b958a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_95ee43f0e2fc4925a900e243494d4ba7","placeholder":"​","style":"IPY_MODEL_d6819a44e4414a0eac42a186dd97f246","value":" 8/951 [04:17\u0026lt;8:22:57, 32.00s/it]"}},"7481afa84a814dedb6877f57cfebcc3c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1a3254f7b9342859b23e530418486ee","placeholder":"​","style":"IPY_MODEL_9b395ebf79ea4b6781415e599688c761","value":"  1%"}},"773e2938bc3a43db9a7aa97d90d4757a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95ee43f0e2fc4925a900e243494d4ba7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b395ebf79ea4b6781415e599688c761":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a1a3254f7b9342859b23e530418486ee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1d0ef825d4b47ab870ac88b78fee830":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d6819a44e4414a0eac42a186dd97f246":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}